{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pyglet\n",
    "\n",
    "\n",
    "MISURAZIONI = 10\n",
    "SOGLIA = 10\n",
    "\n",
    "stato_occhi = {'rilevamenti': [2]*MISURAZIONI, 'occhi_chiusi': False}\n",
    "\n",
    "def check(occhi_trovati):\n",
    "    \n",
    "    stato_occhi['rilevamenti'].append(occhi_trovati)\n",
    "    stato_occhi['rilevamenti'].pop(0)\n",
    "    numero_occhi = sum(stato_occhi['rilevamenti'])\n",
    "    \n",
    "    if numero_occhi > SOGLIA:\n",
    "        stato_occhi['occhi_chiusi'] = False\n",
    "    else:\n",
    "        stato_occhi['occhi_chiusi'] = True\n",
    "        \n",
    "        \n",
    "def cambia_colore(immagine, pixels, B, G, R):\n",
    "    for (w,k) in pixels:\n",
    "        immagine[w][k] = [B, G, R]\n",
    "        \n",
    "        \n",
    "def draw(img1, img2, i, j):          # i = coordinata verticale, j = orizzontale\n",
    "    h,w, _ = img2.shape\n",
    "    img1[i:i+h, j:j+w] = img2[:h, :w]\n",
    "    \n",
    "    \n",
    "def main_face(facce):                # restituisce i parametri della faccia piÃ¹ estesa rilevata nell'immagine\n",
    "    fx = facce[0][0]\n",
    "    fy = facce[0][1]\n",
    "    fw = facce[0][2]\n",
    "    fh = facce[0][3]\n",
    "    \n",
    "    for [x, y, w, h] in facce:\n",
    "        if w*h > fw*fh:\n",
    "            fx = x\n",
    "            fy = y\n",
    "            fw = w\n",
    "            fh = h\n",
    "    return fx, fy, fw, fh\n",
    "\n",
    "        \n",
    "face_cascade = cv2.CascadeClassifier('../Assets/lib/faccia.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('../Assets/lib/occhiali.xml')\n",
    "        \n",
    "cv2.VideoCapture(0)\n",
    "cap = cv2.VideoCapture(0) \n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 320) \n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 240)\n",
    "\n",
    "quadro = cv2.imread('../Assets/Img/quadro.png')\n",
    "start = cv2.imread('../Assets/Img/start.png')\n",
    "guida_sicura = cv2.imread('../Assets/Img/guida_sicura.png')\n",
    "guida_distratta = cv2.imread('../Assets/Img/distrazione.png')\n",
    "pericolo = cv2.imread('../Assets/Img/Pericolo.png')\n",
    "triangolo = cv2.imread('../Assets/Img/Allarme_sonno.png')\n",
    "triangolo_giallo = cv2.imread('../Assets/Img/attenzione_giallo.png')\n",
    "occhi_aperti = cv2.imread('../Assets/Img/occhi_aperti.png')\n",
    "sound = pyglet.media.load('../Assets/audio/avviso.mp3')\n",
    "sound2 = pyglet.media.load('../Assets/audio/avviso2.mp3')\n",
    "pixels = np.loadtxt('../Assets/files/pixels_quadro.txt', dtype = 'int')\n",
    "\n",
    "\n",
    "draw(quadro, start, 100, 370)\n",
    "\n",
    "looper = pyglet.media.SourceGroup(sound.audio_format, None)          #crea looper audio (occhi chiusi)\n",
    "looper.loop = True\n",
    "looper.queue(sound)\n",
    "avviso = pyglet.media.Player()\n",
    "avviso.queue(looper)\n",
    "\n",
    "looper2 = pyglet.media.SourceGroup(sound2.audio_format, None)          #crea looper audio 2 (distrazione)\n",
    "looper2.loop = True\n",
    "looper2.queue(sound2)\n",
    "avviso2 = pyglet.media.Player()\n",
    "avviso2.queue(looper2)\n",
    "\n",
    "distrazione = False\n",
    "\n",
    "while cv2.waitKey(30) != ord('s'):\n",
    "    cv2.imshow('C.C.A.S.A.: Car Concentration And Security Assistant', quadro)\n",
    "else:\n",
    "    draw(quadro, guida_sicura, 100, 370) \n",
    "    cambia_colore(quadro, pixels, 150, 210, 190)\n",
    "    \n",
    "while cv2.waitKey(30) != ord('q'):\n",
    "    ret, camera = cap.read()\n",
    "        \n",
    "    gray = cv2.cvtColor(camera, cv2.COLOR_BGR2GRAY)\n",
    "    faccia = face_cascade.detectMultiScale(gray, 1.3, 5)   \n",
    "    \n",
    "    \n",
    "    if len(faccia) != 0:\n",
    "        fx, fy, fw, fh = main_face(faccia)\n",
    "        \n",
    "        cv2.rectangle(camera,(fx,fy),(fx+fw,fy+fh),(150,210,190), 1)   \n",
    "        \n",
    "        roi_gray = gray[fy:fy+fh, fx:fx+fw]\n",
    "        roi_color = camera[fy:fy+fh, fx:fx+fw]\n",
    "        \n",
    "        occhi = eye_cascade.detectMultiScale(roi_gray, maxSize=(int(fw/5),int(fh/5)), minSize=(int(fw/7),int(fh/7)))\n",
    "        \n",
    "        check(len(occhi))\n",
    "        \n",
    "        for [ex,ey,ew,eh] in occhi:                                   \n",
    "            cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh), (150,210,190), 1)\n",
    "        \n",
    "        avviso2.pause()\n",
    "        draw(quadro, guida_sicura, 100, 370)\n",
    "        draw(quadro, occhi_aperti, 500, 455)\n",
    "        \n",
    "    else:\n",
    "        draw(quadro, guida_distratta, 100, 370)\n",
    "        draw(quadro, triangolo_giallo, 500, 455)\n",
    "        avviso2.play()\n",
    "        \n",
    "    if stato_occhi['occhi_chiusi']:\n",
    "        avviso.play()\n",
    "        draw(quadro, pericolo, 100, 370)\n",
    "        draw(quadro, triangolo, 500, 455)\n",
    "    else:\n",
    "        avviso.pause()\n",
    "        \n",
    "        \n",
    "    draw(quadro, camera, 235, 375)        \n",
    "    cv2.imshow('C.C.A.S.A.: Car Concentration And Security Assistant', quadro)\n",
    "\n",
    "avviso.pause()\n",
    "avviso2.pause()\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
