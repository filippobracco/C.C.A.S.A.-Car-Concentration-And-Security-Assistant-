{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C.C.A.S.A.: Car Concentration And Security Assistant\n",
    "Bracco Filippo & Di Vece Chiara \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduzione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stanchezza, nervosismo, distrazione e sonnolenza sono le cause di oltre il 66% degli incidenti. Questi dati allarmanti ci hanno indotto a pensare un dispositivo che possa evitare incidenti di questa natura, verificando oggettivamente che il conducente sia sempre concentrato sulla strada. Lo scopo del programma è quello di rilevare particolari condizioni  non compatibili con una guida sicura attraverso il rilevamento dei tratti del viso e, in particolar modo, degli occhi, accertandosi che lo sguardo sia rivolto verso la strada mentre il veicolo è in movimento.\n",
    "In seguito risponderà adeguatamente per richiamare all’attenzione il guidatore con avvisi acustici e visivi. \n",
    "Lo scopo principale è quello di evitare molti incidenti e poter salvare molte vite. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si importano le librerie:\n",
    "* **CV2**: libreria open-source per la gestione di immagini e video;\n",
    "* **NUMPY**: libreria per calcolo scientifico;\n",
    "* **PYGLET**: libreria per la gestione di immagini, video e suoni (utilizzata in questo codice solo per questi ultimi)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pyglet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definizione costanti\n",
    "**MISURAZIONI** e **SOGLIA** sono utilizzate per discriminare lo stato di *occhi aperti* oppure *occhi chiusi*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MISURAZIONI = 10 \n",
    "SOGLIA = 10  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variabili globali"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**stato_occhi**: è un dizionario formato da:\n",
    "* la lista *'rilevamenti'*, contenente il numero di occhi rilevati nelle ultime misurazioni (la cardinalità della lista è definita dalla costante *MISURAZIONI*), iniazialmente la lista è riempita di 2 (condizione normale);\n",
    "* la variabile booleana *'occhi_chiusi'* che descrive lo stato corrente degli occhi. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stato_occhi = {'rilevamenti': [2]*misurazioni, 'occhi_chiusi': False} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definizione funzioni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) La funzione **check** ha come parametro in ingresso un intero **occhi_trovati** che rappresenta il numero di occhi rilevati in un singolo frame. Lo scopo è quello di aggiornare la variabile globale *stato_occhi*: \n",
    "* viene aggiunto il valore acquisito in coda alla lista *'rilevamenti'* del dizionario;\n",
    "* viene rimosso il primo elemento della suddetta lista (ovvero la rilevazione più vecchia tra quelle salvate);\n",
    "* viene calcolata la somma dei rilevamenti nella lista;\n",
    "* se il numero è superiore alla soglia definita, gli occhi sono aperti, quindi si assegna alla variabile *'occhi_chiusi'* del dizionario il valore *False*, *True* altrimenti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check(occhi_trovati):\n",
    "    \n",
    "    stato_occhi['rilevamenti'].append(occhi_trovati)\n",
    "    stato_occhi['rilevamenti'].pop(0)\n",
    "    numero_occhi = sum(stato_occhi['rilevamenti'])\n",
    "    \n",
    "    if numero_occhi > SOGLIA:\n",
    "        stato_occhi['occhi_chiusi'] = False\n",
    "    else:\n",
    "        stato_occhi['occhi_chiusi'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) La funzione **cambia_colore** serve a cambiare il colore di pixel specifici di un'immagine. I parametri di ingresso sono l'immagine **immagine**, una lista, **pixels**, contenente le coppie di coordinate relative ai pixel il cui valore deve essere cambiato, e tre interi, **B**, **G** e **R**, che rappresentano il valore da assegnare ai pixel dell'immagine contenuti nella lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cambia_colore(immagine, pixels, B, G, R): \n",
    "    for (w,k) in pixels:\n",
    "        immagine[w][k] = [B, G, R]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) La funzione **draw** serve a sovrascrivere un'immagine su un'altra più grande a partire da una precisa posizione. Essa riceve in ingresso l'immagine base **img1**, la seconda immagine **img2** e due interi, **i** e **j**, che rappresentano la coordinata dell'immagine base dalla quale iniziare a copiare la seconda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw(img1, img2, i, j):          #i = coordinata verticale, j = orizzontale\n",
    "    h,w, _ = img2.shape\n",
    "    img1[i:i+h, j:j+w] = img2[:h, :w] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) La funzione **main_face** ha come parametro in ingresso la lista **facce**. Essa contiene uno o più elementi, ognuno dei quali rappresenta una faccia rilevata nell'immagine in ingresso dalla camera; ogni elemento è una lista di quattro valori che caratterizzano la regione dell'immagine in cui è presente il volto, ovvero posizione orizzontale, posizione verticale, larghezza e altezza. La funzione restituisce i quattro parametri (**fx**, **fy**, **fw** e **fh**) della faccia con le dimensioni maggiori tra quelle contenute nella nella lista. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main_face(facce):                # restituisce i parametri della faccia più estesa rilevata nell'immagine\n",
    "    fx = facce[0][0]\n",
    "    fy = facce[0][1]\n",
    "    fw = facce[0][2]\n",
    "    fh = facce[0][3]\n",
    "    \n",
    "    for [x, y, w, h] in facce:\n",
    "        if w*h > fw*fh:\n",
    "            fx = x\n",
    "            fy = y\n",
    "            fw = w\n",
    "            fh = h\n",
    "    return fx, fy, fw, fh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caricamento dati"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si caricano i file relativi alle funzioni di classificazione per faccia e occhi (materiale OpenCV)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('../Assets/lib/faccia.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('../Assets/lib/occhiali.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si utilizza la funzione di **cv2** per consentire l'accesso alla web cam e si setta le dimensioni dell'immagine in ingresso a 320x240 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv2.VideoCapture(0)\n",
    "cap = cv2.VideoCapture(0) \n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 320) \n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 240)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si importano le immagini e i suoni utilizzati nel programma. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "quadro = cv2.imread('../Assets/Img/quadro.png')\n",
    "start = cv2.imread('../Assets/Img/start.png')\n",
    "guida_sicura = cv2.imread('../Assets/Img/guida_sicura.png')\n",
    "guida_distratta = cv2.imread('../Assets/Img/distrazione.png')\n",
    "pericolo = cv2.imread('../Assets/Img/Pericolo.png')\n",
    "triangolo = cv2.imread('../Assets/Img/Allarme_sonno.png')\n",
    "triangolo_giallo = cv2.imread('../Assets/Img/attenzione_giallo.png')\n",
    "occhi_aperti = cv2.imread('../Assets/Img/occhi_aperti.png')\n",
    "sound = pyglet.media.load('../Assets/audio/avviso.mp3')\n",
    "sound2 = pyglet.media.load('../Assets/audio/avviso2.mp3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'immagine di base sulla quale vengono sovrascritte le altre secondarie è quella del quadro:\n",
    "\n",
    "![Quadro](../Assets/Img/quadro.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si carica un file di testo contenente coppie di numeri interi che rappresentano le posizioni dei pixel del quadro da cambiare all'accensione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pixels = np.loadtxt('../Assets/files/pixels_quadro.txt', dtype = 'int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per creare il file si sono salvate le posizioni dei pixel del quadro con valore (70, 60, 60), che rappresenta il colore del quadro spento, in una lista, la quale è stata poi salvata su file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![File_pixels](../Assets/Img/file_img.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inizializzazione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viene stampata sul quadro l'immagine *start* in posizione (100, 370) dell'immagine *quadro* tramite la funzione **draw**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "draw(quadro, start, 100, 370)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Start](../Assets/Img/start.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si utilizzano le funzioni di **Pyglet** per la gestione degli audio: vengono creati due oggetti audio, **avviso** e  **avviso2**, che possono essere avviati e messi in pausa nel corpo del programma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "looper = pyglet.media.SourceGroup(sound.audio_format, None)          #crea looper audio (occhi chiusi)\n",
    "looper.loop = True\n",
    "looper.queue(sound)\n",
    "avviso = pyglet.media.Player()\n",
    "avviso.queue(looper)\n",
    "\n",
    "looper2 = pyglet.media.SourceGroup(sound2.audio_format, None)          #crea looper audio 2 (distrazione)\n",
    "looper2.loop = True\n",
    "looper2.queue(sound2)\n",
    "avviso2 = pyglet.media.Player()\n",
    "avviso2.queue(looper2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viene definita la variabile booleana **distrazione** e assegnato il valore *False* all'inizio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "distrazione = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpo codice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inizio di un ciclo **while** che stampa a schermo (tramite apposita funzione dell'ambiente) l'immagine **quadro** (*spento*) finchè su tastiera non viene premuto il tasto '**s**'. Premuto il tasto viene inserita nel quadro l'immagine **guida sicura** e viene cambiato il colore dei pixel del quadro (accensione). ![Guida sicura](../Assets/Img/guida_sicura.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "while cv2.waitKey(30) != ord('s'):\n",
    "    cv2.imshow('Car Concentration And Security Assistant', quadro)\n",
    "else:\n",
    "    draw(quadro, guida_sicura, 100, 370) \n",
    "    cambia_colore(quadro, pixels, 150, 210, 190)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In questa porzione di codice si entra in un nuovo ciclo **while** finchè non si preme su tastiera il tasto '**q**', le operazioni svolte sono:\n",
    "* si acquisisce l'immagine dalla webcam tramite la funzione **read()**;\n",
    "* si applica il filtro **BRG2GRAY** della libreria **CV2** all'immagine acquisita per poter utilizzare i classificatori;\n",
    "* si utilizza il classificatore della faccia, il quale restituisce una lista pari al numero di facce trovate e ogni elemento di questa contiene un'ulteriore lista di quattro elementi: posizione verticale, posizione orizzontale, larghezza e altezza della regione di interesse;\n",
    "* se la lista **faccia** non è vuota si cercano gli attributi della faccia rilevata più estesa (tramite la funzione **main_face** definita precedemtemente) e si riquadra l'area contenente tale volto con l'apposita funzione di **cv2**;\n",
    "* all'interno della sola regione di interesse (dove è presente la faccia) si procede alla ricerca degli occhi;\n",
    "* si invoca la funzione **check** per aggiornare lo stato degli occhi passandole in ingresso il numero di occhi rilevati;\n",
    "* ogni occhio viene riquadrato;\n",
    "* sul quadro vengono sovrascritte le immagini che segnalano la *guida sicura* e gli *occhi aperti* e si mette in pausa l'audio relativo alla distrazione **avviso2**\n",
    "\n",
    "![occhi aperti](../Assets/Img/occhi_aperti.png)\n",
    "\n",
    "* se, invece, la lista **faccia** è vuota viene eseguito solo il ramo **else** e si si genera un avviso di distrazione visivo (immagini sul quadro) e sonoro (si avvia audio):\n",
    "\n",
    "![Distrazione](../Assets/Img/distrazione.png)\n",
    "\n",
    "![Triangolo giallo](../Assets/Img/attenzione_giallo.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "while cv2.waitKey(30) != ord('q'):\n",
    "    ret, camera = cap.read()\n",
    "        \n",
    "    gray = cv2.cvtColor(camera, cv2.COLOR_BGR2GRAY)\n",
    "    faccia = face_cascade.detectMultiScale(gray, 1.3, 5)   \n",
    "    \n",
    "    \n",
    "    if len(faccia) != 0:\n",
    "        fx, fy, fw, fh = main_face(faccia)\n",
    "        \n",
    "        cv2.rectangle(camera,(fx,fy),(fx+fw,fy+fh),(150,210,190), 1)   \n",
    "        \n",
    "        roi_gray = gray[fy:fy+fh, fx:fx+fw]\n",
    "        roi_color = camera[fy:fy+fh, fx:fx+fw]\n",
    "        \n",
    "        occhi = eye_cascade.detectMultiScale(roi_gray, maxSize=(int(fw/5),int(fh/5)), minSize=(int(fw/7),int(fh/7)))\n",
    "        \n",
    "        check(len(occhi))\n",
    "        \n",
    "        for [ex,ey,ew,eh] in occhi:                                   \n",
    "            cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh), (150,210,190), 1)\n",
    "        \n",
    "        avviso2.pause()\n",
    "        draw(quadro, guida_sicura, 100, 370)\n",
    "        draw(quadro, occhi_aperti, 500, 455)\n",
    "        \n",
    "    else:\n",
    "        draw(quadro, guida_distratta, 100, 370)\n",
    "        draw(quadro, triangolo_giallo, 500, 455)\n",
    "        avviso2.play()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seguire si verifica lo stato occhi e si aggiorna opportunamente l'output:\n",
    "\n",
    "* se nel dizionario **'stato_occhi'** la variabile **occhi_chiusi** è Vera si genera un avviso adeguato visivo (immagini sul quadro) e sonoro (si avvia audio):\n",
    "\n",
    "![sonno](../Assets/Img/Allarme_sonno.png) ![pericolo](../Assets/Img/Pericolo.png)\n",
    "\n",
    "altrimenti viene messo in pausa l'audio relativo agli occhi chiusi (**avviso**).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    if stato_occhi['occhi_chiusi']:\n",
    "        avviso.play()\n",
    "        draw(quadro, pericolo, 100, 370)\n",
    "        draw(quadro, triangolo, 500, 455)\n",
    "    else:\n",
    "        avviso.pause()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alla fine del ciclo si sovrappone all'immagine del quadro quella ricevuta in input dalla camera, con faccia e occhi eventualmente riquadrati, e viene mostrato a video l'immagine **quadro**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    draw(quadro, camera, 235, 375)\n",
    "    cv2.imshow('Car Concentration And Security Assistant', quadro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terminazione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al termine del ciclo precedente, avvenuto premendo da tastiera il tasto '**q**', vengono messi in pausa gli avvisi, nel caso in cui fossero in fase di *play*, e chiuse tutte le finestre aperte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avviso.pause()\n",
    "avviso2.pause()\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonti "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sito [OpenCV](http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_gui/py_image_display/py_image_display.html) per la consultazione della documentazione sulle funzioni della libreria *cv2*;\n",
    "* Download dei [classificatori](https://github.com/opencv/opencv/tree/master/data/haarcascades)\n",
    "* Funzionamento algoritmi di tipo Cascade per la [Face Detection](http://docs.opencv.org/master/d7/d8b/tutorial_py_face_detection.html#gsc.tab=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
